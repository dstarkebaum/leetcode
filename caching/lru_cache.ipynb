{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache Fundamentals\n",
    "The idea behind caching is quite simple:\n",
    "- Store data that is often needed somewhere that can be retrieved very fast.\n",
    "\n",
    "Caches should to be fast along two dimensions:\n",
    "1. **Maximum use**: Ensure that as many requests as possible go to it (*cache hit*), not to main memory (*cache miss*)\n",
    "2. **Small overhead**: testing membership and deciding when to replace an should be as fast as possible.\n",
    "\n",
    "In general, you must pre-define the size of your cache, and implement a strategy for what items to keep and what items to evict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRU Cache\n",
    "A **Least Recently Used (LRU) Cache** organizes items in *order of use*, allowing you to quickly identify which item hasn't been used for the longest amount of time.\n",
    "https://www.interviewcake.com/concept/java/lru-cache\n",
    "\n",
    "- Picture a clothes rack, where clothes are always hung up on one side. To find the least-recently used item, look at the item on the other end of the rack.\n",
    "\n",
    "#### Strengths:\n",
    "- **Super fast access.** LRU caches store items in order from most-recently used to least-recently used. That means both can be accessed in O(1) time.\n",
    "\n",
    "- **Super fast updates.** Each time an item is accessed, updating the cache takes O(1) time.\n",
    "\n",
    "#### Weaknesses:\n",
    "- **Space heavy.** An LRU cache tracking *n* items requires a linked list of length *n*, AND a hash map holding *n* items. That's O(n) space, but it's still two data structures (as opposed to one).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Explore a bit first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 3, value: 3, order: 0\n",
      "key: 2, value: 2, order: 1\n",
      "key: 1, value: 1, order: 2\n"
     ]
    }
   ],
   "source": [
    "# Your LRUCache object will be instantiated and called as such:\n",
    "lru = LRUCache(3)\n",
    "lru.put(1,1)\n",
    "lru.put(2,2)\n",
    "lru.put(3,3)\n",
    "\n",
    "see_inside(lru)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 2, value: 4, order: 0\n",
      "key: 3, value: 3, order: 1\n",
      "key: 1, value: 1, order: 2\n"
     ]
    }
   ],
   "source": [
    "lru.put(2,4)\n",
    "see_inside(lru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 5, value: 5, order: 0\n",
      "key: 2, value: 4, order: 1\n",
      "key: 3, value: 3, order: 2\n"
     ]
    }
   ],
   "source": [
    "lru.put(5,5)\n",
    "see_inside(lru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 3, value: 3, order: 0\n",
      "key: 5, value: 5, order: 1\n",
      "key: 2, value: 4, order: 2\n"
     ]
    }
   ],
   "source": [
    "lru.get(3)\n",
    "see_inside(lru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 7, value: 7, order: 0\n",
      "key: 3, value: 3, order: 1\n",
      "key: 5, value: 5, order: 2\n"
     ]
    }
   ],
   "source": [
    "lru.put(7,7)\n",
    "see_inside(lru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation:\n",
    "\n",
    "- Under the hood, an LRU cache is often implemented by pairing a *doubly-linked list* with a *hash map*. (OrderedDict in Python)\n",
    "\n",
    "![ordered-dict](img/ordered-dict.png)\n",
    "\n",
    "## Accessing and Evicting\n",
    "\n",
    "Here are the steps we'd run through each time an item was accessed:\n",
    "\n",
    "1. Look up the item in our hash map.\n",
    "\n",
    "  1. If the item is in the hash table, then it's already in our cache—this is called a \"*cache hit*\"\n",
    "\n",
    "  2. Use the hash table to quickly find the corresponding linked list node.\n",
    "\n",
    "  3. Move the item's linked list node to the head of the linked list, since it's now the most recently used (so it shouldn't get evicted any time soon).\n",
    "\n",
    "2. If the item isn't in the hash table, we have a \"*cache miss*\". We need to load the item into the cache:\n",
    "\n",
    "  1. Create a new linked list node for the item. Insert it at the head of the linked list.\n",
    "\n",
    "  2. Add the item to our hash map, storing the newly-created linked list node as the value.\n",
    "\n",
    "  3. Is our cache full? If so, we need to evict something:\n",
    "\n",
    "    1. Grab the least-recently used cache item—it'll be at the tail of the linked list.\n",
    "\n",
    "    2. Evict that item from the cache by removing it from the linked list and the hash map.\n",
    "    \n",
    "Keeping all the pointers straight as you move around linked list nodes is tricky!\n",
    "\n",
    "All of those steps are O(1), so put together it takes O(1) time to update our cache each time an element is accessed. Pretty cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest solution from LeetCode, extending OrderedDict\n",
    "class LRUCacheOD(OrderedDict):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        \"\"\"\n",
    "        :type capacity: int\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def get(self, key):\n",
    "        \"\"\"\n",
    "        :type key: int\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        \n",
    "        # if the key was not found return -1\n",
    "        if key not in self:\n",
    "            return - 1\n",
    "        \n",
    "        # since we accessed the key, move it to the end so it will stay in the cache longer\n",
    "        self.move_to_end(key)\n",
    "        \n",
    "        # return the value\n",
    "        return self[key]\n",
    "\n",
    "    def put(self, key, value):\n",
    "        \"\"\"\n",
    "        :type key: int\n",
    "        :type value: int\n",
    "        :rtype: void\n",
    "        \"\"\"\n",
    "        # if the key already in the dict\n",
    "        if key in self:\n",
    "            # it was accessed, so move it to the end so it stays in the cache longer!\n",
    "            self.move_to_end(key)\n",
    "        \n",
    "        # reset the value if it already existed, or create a new key-value pair if it did not\n",
    "        self[key] = value\n",
    "        \n",
    "        # check to see if we are over capacity (now that we may have already added a new item)\n",
    "        if len(self) > self.capacity:\n",
    "            \n",
    "            # if so, we have to evict an item!\n",
    "            # the 'last' flag refers to if you want the last item added (like a stack). \n",
    "            # In this case we actually want to the first item added (like a queue).\n",
    "            self.popitem(last = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple node object for a doubly linked list\n",
    "# Each node keeps track of a key/value and pointers to the next and prev nodes\n",
    "class Node:\n",
    "    def __init__(self, k, v):\n",
    "        self.key = k\n",
    "        self.val = v\n",
    "        self.prev = None\n",
    "        self.next = None\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, capacity):\n",
    "        \"\"\"\n",
    "        :type capacity: int\n",
    "        \"\"\"\n",
    "        self.capacity = capacity\n",
    "        self.dic = dict()\n",
    "        # a neat trick where the cache object itself keeps track of the\n",
    "        # head and tail directly (acting like a sentinel node)\n",
    "        # self.prev refers to the front of the LL (most recently added)\n",
    "        # and self.next refers to the end (next in line for deletion)\n",
    "        self.prev = self.next = self\n",
    "\n",
    "    # when you add a new node, put it in the front of the LL\n",
    "    def _add(self, node):\n",
    "        # self.prev refers to the old front of the LL\n",
    "        p = self.prev\n",
    "        # now that node points to our new node\n",
    "        p.next = node\n",
    "\n",
    "        # the cache object must update its pointer so the front points to our new node\n",
    "        self.prev = node\n",
    "\n",
    "        # and our new node's prev to the old front of the LL\n",
    "        node.prev = p\n",
    "        # and the next points to the cache object (like a sentinel)\n",
    "        node.next = self\n",
    "\n",
    "    # when removing a node, you just bypass the pointers to it\n",
    "    # and let the garbage collector handle the rest\n",
    "    def _remove(self, node):\n",
    "        p = node.prev\n",
    "        n = node.next\n",
    "        p.next = n\n",
    "        n.prev = p\n",
    "\n",
    "    # when you access a key, you need to move that node to the front\n",
    "    # so it will not be deleted soon\n",
    "    def get(self, key):\n",
    "        \"\"\"\n",
    "        :type key: int\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        # first check if the key even exists!\n",
    "        if key in self.dic:\n",
    "            # if it was found, get a pointer to the correct node from the dict\n",
    "            n = self.dic[key]\n",
    "            # then remove all links to that node\n",
    "            self._remove(n)\n",
    "            # and add it to the front of the LL\n",
    "            self._add(n)\n",
    "            # finally, return the value that was asked for\n",
    "            return n.val\n",
    "\n",
    "        # if the key was not found return -1\n",
    "        return -1\n",
    "\n",
    "    # When you put a new value in, you also move it to the front of the list\n",
    "    def put(self, key, value):\n",
    "        \"\"\"\n",
    "        :type key: int\n",
    "        :type value: int\n",
    "        :rtype: None\n",
    "        \"\"\"\n",
    "        # if the value was already found\n",
    "        if key in self.dic:\n",
    "            # we want to remove links to the node that currenly holds its value\n",
    "            # so that we can just recreate it at the front of the LL\n",
    "            self._remove(self.dic[key])\n",
    "        # make a new node to store the key/value pair\n",
    "        n = Node(key, value)\n",
    "\n",
    "        # add that node to the LL (inserting it to the front)\n",
    "        self._add(n)\n",
    "        # point the dictionary to that new node\n",
    "        # note that if the key already existed, we are just reassigning its value\n",
    "        self.dic[key] = n\n",
    "\n",
    "        # If we added a new entry to our dictionary, we may be over capacity now\n",
    "        if len(self.dic) > self.capacity:\n",
    "            # in that case, we want to remove the last node added\n",
    "            # which will be referenced by self.next (the tail of the LL)\n",
    "            n = self.next\n",
    "            # then we remove the pointers to that node\n",
    "            self._remove(n)\n",
    "            # and remove it from the dictionary\n",
    "            # at this point, there will really be no more pointers to that node\n",
    "            # and the garbage collector will get rid of it.\n",
    "            del self.dic[n.key]\n",
    "\n",
    "def see_inside(lru):\n",
    "    n = lru.prev\n",
    "    for i in range(len(lru.dic)):\n",
    "        print('key: '+str(n.key)+', value: '+str(n.val)+', order: '+str(i))\n",
    "        n = n.prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
